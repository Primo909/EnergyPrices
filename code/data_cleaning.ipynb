{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Data from the ENTSO-E API and the weather data must be cleaned, combined and then saved to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/jakagodec/Desktop/ist/es/project3/EnergyPrices/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "Below are functions to load and transform data from each raw file. Mostly they just set a `DatetimeIndex` and rename some columns. The biggest exception is the unavailability data which has to be transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(code):\n",
    "    country_path = path + 'data/' + code + '_raw/' + code\n",
    "    df_prices = pd.read_csv(country_path + '_prices.csv')\n",
    "    df_prices['Time'] = pd.to_datetime(pd.to_datetime(df_prices['Unnamed: 0']), utc=True)\n",
    "    \n",
    "    return df_prices.set_index('Time').drop('Unnamed: 0', axis=1).rename({'0': 'DayAheadPrice'}, axis=1)\n",
    "\n",
    "def get_generation(code):\n",
    "    country_path = path + 'data/' + code + '_raw/' + code\n",
    "    df_generation = pd.read_csv(country_path + '_generation.csv')\n",
    "    df_generation['Time'] = pd.to_datetime(pd.to_datetime(df_generation['Unnamed: 0']), utc=True)\n",
    "    map_generation = {\n",
    "        'Biomass': 'GenBiomass', \n",
    "        'Fossil Brown coal/Lignite': 'GenFossilBrownCoal', \n",
    "        'Fossil Gas': 'GenFossilGas', \n",
    "        'Fossil Oil': 'GenFossilOil',\n",
    "        'Fossil Hard coal': 'GenFossilHardCoal',\n",
    "        'Hydro Pumped Storage': 'GenHydroPumped', \n",
    "        'Hydro Pumped Storage.1': 'GenHydroPumpedOther',\n",
    "        'Hydro Run-of-river and poundage': 'GenHydroRiver',\n",
    "        'Hydro Water Reservoir': 'GenHydroReservoir',\n",
    "        'Nuclear': 'GenNuclear',\n",
    "        'Geothermal': 'GenGeothermal',\n",
    "        'Other renewable': 'GenOtherRenewable',\n",
    "        'Solar': 'GenSolar', \n",
    "        'Waste': 'GenWaste', \n",
    "        'Wind Onshore': 'GenWind',\n",
    "        'Other': 'GenOther'\n",
    "        }\n",
    "    \n",
    "    return df_generation.set_index('Time').drop('Unnamed: 0', axis=1).rename(map_generation, axis=1)\n",
    "\n",
    "\n",
    "def get_import(code):\n",
    "    country_path = path + 'data/' + code + '_raw/' + code\n",
    "    df_import = pd.read_csv(country_path + '_import.csv')\n",
    "    df_import['Time'] = pd.to_datetime(pd.to_datetime(df_import['Unnamed: 0']), utc=True)\n",
    "    df_import = df_import.set_index('Time').drop('Unnamed: 0', axis=1).fillna(0).resample('H').sum()\n",
    "    map_import = {col: 'Import' + col for col in df_import.columns}\n",
    "    df_import.rename(map_import, axis=1, inplace=True)\n",
    "    \n",
    "    return df_import\n",
    "\n",
    "def get_loads(code):\n",
    "    country_path = path + 'data/' + code + '_raw/' + code\n",
    "    df_load = pd.read_csv(country_path + '_load.csv')\n",
    "    df_load['Time'] = pd.to_datetime(pd.to_datetime(df_load['Unnamed: 0']), utc=True)\n",
    "    map_load = {'Forecasted Load': 'LoadForecast', 'Actual Load': 'LoadActual'}\n",
    "    \n",
    "    return df_load.set_index('Time').drop('Unnamed: 0', axis=1).rename(map_load, axis=1)\n",
    "\n",
    "\n",
    "def get_unavailability(code):\n",
    "    global_start = pd.to_datetime(pd.Timestamp('20220101', tz='CET'), utc=True)\n",
    "    global_end = pd.to_datetime(pd.Timestamp('20230301', tz='CET'), utc=True)\n",
    "    global_index = pd.date_range(global_start, global_end, freq='h')\n",
    "\n",
    "    sum = pd.Series(np.zeros(global_index.shape[0]), index=global_index)\n",
    "\n",
    "    df = pd.read_csv(path + 'data/' + code + '_raw/' + code + '_unavailability.csv')#[['start', 'end', 'nominal_power']]\n",
    "    for row in df.index:\n",
    "        t_start = pd.to_datetime(pd.to_datetime(df.loc[row, 'start']), utc=True)\n",
    "        t_end = pd.to_datetime(pd.to_datetime(df.loc[row, 'end']), utc=True)\n",
    "        i = pd.date_range(t_start, t_end, freq='h')\n",
    "        val = df.loc[row, 'nominal_power'] * np.ones(i.shape[0])\n",
    "        sum = sum.add(pd.Series(val, index=i), fill_value=0)\n",
    "\n",
    "    return pd.DataFrame(sum.reindex(global_index, fill_value=0), columns=['PowerUnavailable'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(code):\n",
    "    country_path = path + 'data/' + code + '_raw/' + code\n",
    "\n",
    "    df = pd.read_excel(country_path + '_weather.xlsx')\n",
    "    map = {\n",
    "        'latitude': 'Time',\n",
    "        'longitude': 'Temperature',\n",
    "        'elevation': 'Precipitation',\n",
    "        'utc_offset_seconds': 'SolarRad'\n",
    "    }\n",
    "    df = df.loc[3:].drop(['timezone', 'timezone_abbreviation'], axis=1).rename(map, axis=1)\n",
    "    return df.set_index(pd.to_datetime(pd.to_datetime(df['Time']), utc=True)).drop('Time', axis=1).iloc[:-24]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data\n",
    "Function below loads and joins all files for given country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(code):\n",
    "    df_prices = get_prices(code)\n",
    "    df_generation = get_generation(code)\n",
    "    df_import = get_import(code)\n",
    "    df_load = get_loads(code)\n",
    "    df_weather = get_weather(code)\n",
    "\n",
    "    # join and return\n",
    "    df_main = df_prices.merge(\n",
    "        df_generation, \n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    ).merge(\n",
    "            df_import, \n",
    "            left_index=True, \n",
    "            right_index=True\n",
    "        ).merge(\n",
    "                df_load, \n",
    "                left_index=True, \n",
    "                right_index=True\n",
    "            ).merge(\n",
    "                    df_weather,\n",
    "                    left_index=True,\n",
    "                    right_index=True\n",
    "                )\n",
    "    \n",
    "    if code.lower() != 'hr':\n",
    "        df_unav = get_unavailability(code)\n",
    "    \n",
    "        return df_main.merge(df_unav, left_index=True, right_index=True)\n",
    "    \n",
    "    return df_main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "Data for a single country (`pandas.DataFrame`) is saved as a pickle (`.pkl`) file as it can then be loaded as a `pandas.DataFrame` immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['SI', 'HR', 'RS', 'RO', 'GR', 'BG']\n",
    "\n",
    "for c in codes:\n",
    "    df = clean_data(c)\n",
    "    fname = path + 'data/clean/' + c + '_clean.pkl'\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
